{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af320fd-1cd6-4bc6-a940-b241e0458cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import collections\n",
    "import re\n",
    "from scipy.optimize import minimize\n",
    "from scipy.integrate import quad\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db4ba92-6850-43e6-b65a-a27a04289294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def read_brown_corpus_files(directory=\"C:\\\\Users\\\\saidk\\\\Курсач Python\\\\brown\"):\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Error: Directory '{directory}' not found.\")\n",
    "        return None\n",
    "\n",
    "    files = [f for f in os.listdir(directory) if f.startswith(\"c\")]\n",
    "    corpus_texts = dict()\n",
    "    for file in files:\n",
    "        filepath = os.path.join(directory, file)\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                corpus_texts[file] = [f.read()]\n",
    "        except (FileNotFoundError, UnicodeDecodeError) as e:\n",
    "            print(f\"Error reading file {filepath}: {e}\")\n",
    "    return corpus_texts\n",
    "\n",
    "def parse_text_to_words(text):\n",
    "    # Удаляет лишние знаки пунктуации и разделает текст на слова.\n",
    "    text = re.sub(r'/\\w+', '', text) \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = text.lower().split()\n",
    "    \n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26e720-09ed-4bb2-8dd4-65e5d6fd32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_texts = read_brown_corpus_files()\n",
    "print(corpus_texts)\n",
    "if corpus_texts:\n",
    "    all_words = dict()\n",
    "    for key in corpus_texts.keys():\n",
    "        words = parse_text_to_words(*corpus_texts[key])\n",
    "        all_words[key] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f0751e-4f71-402e-a590-85e2adc56a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words[\"ca01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from collections import defaultdict\n",
    "\n",
    "class ZipfMandelbrotMixtureEM:\n",
    "    def __init__(self, data, num_components=2, ns=None, qs=None, ss=None):\n",
    "        self.data = np.array(data)  # Преобразуем data в NumPy array\n",
    "        self.num_data = len(self.data)\n",
    "        self.num_components = num_components\n",
    "        self.pdf_cache = defaultdict(dict) # Кэш для pdf\n",
    "\n",
    "        # Инициализация параметров (без изменений)\n",
    "        if ns is None:\n",
    "            self.ns = np.random.randint(low=self.num_data, high=self.num_data*2, size=num_components)\n",
    "        else:\n",
    "            assert len(ns) == num_components\n",
    "            self.ns = np.array(ns) # Преобразуем в numpy array\n",
    "        if qs is None:\n",
    "            self.qs = np.random.uniform(low=0.0, high=10.0, size=num_components)\n",
    "            print(\"qs \", self.qs)\n",
    "        else:\n",
    "            assert len(qs) == num_components, \"Number of initial qs must match number of components.\"\n",
    "            self.qs = qs\n",
    "        if ss is None:\n",
    "            self.ss = np.random.uniform(low=0.0, high=10.0, size=num_components)\n",
    "            print(\"ss \", self.ss)\n",
    "        else:\n",
    "            assert len(ss) == num_components, \"Number of initial ss must match number of components.\"\n",
    "            self.ss = ss\n",
    "        self.weights = np.full(num_components, 1/num_components)\n",
    "\n",
    "\n",
    "    def pdf(self, x, params):\n",
    "        q, s, n = params\n",
    "        if np.any(x <= 0) or np.any(x > n):\n",
    "            return np.zeros_like(x)\n",
    "\n",
    "        key = (n, q, s)\n",
    "        if key in self.pdf_cache and q in self.pdf_cache[key]:\n",
    "            denominator = self.pdf_cache[key][q]\n",
    "        else:\n",
    "            denominator = np.sum((np.arange(1, n + 1) + q)**(-s))\n",
    "            self.pdf_cache[key][q] = denominator\n",
    "\n",
    "        numerator = (x + q)**(-s)\n",
    "        return numerator / denominator if denominator > 0 else 0\n",
    "\n",
    "    def mix_pdf(self):\n",
    "        return np.sum([self.weights[i] * self.pdf(np.arange(1, max(self.ns)+1, 1), [self.qs[i], self.ss[i], self.ns[i]]) for i in range(self.num_components)], axis = 0)\n",
    "    \n",
    "    def Estep(self):\n",
    "        qs = np.array(self.qs)\n",
    "        ss = np.array(self.ss)\n",
    "        ns = np.array(self.ns)\n",
    "        # print(\"ns: \", ns)\n",
    "        weights = np.array(self.weights)\n",
    "\n",
    "        pdf_values = np.zeros((max(self.ns), self.num_components))\n",
    "        for i in range(self.num_components):\n",
    "            pdf_values[:, i] = pdf_values[:, i] = np.concatenate((self.pdf(np.arange(1, self.ns[i] + 1), [qs[i], ss[i], ns[i]]) * weights[i], np.zeros(int(max(self.ns) - self.ns[i]))))\n",
    "        print(\"wps_all: \", pdf_values)\n",
    "        den = np.sum(pdf_values, axis=1, keepdims=True)\n",
    "        # print(\"den: \", den)\n",
    "        pdf_values /= den\n",
    "        self.loglike = np.sum(np.log(den))\n",
    "        # print(\"pdf_values: \", pdf_values)\n",
    "        return pdf_values\n",
    "\n",
    "\n",
    "    def Mstep(self, weights):\n",
    "        distr_weights = weights\n",
    "        print(distr_weights, distr_weights.shape)\n",
    "        bounds = [(0, 10), (0, 10), (self.num_data, sum(self.data))]\n",
    "        for i in range(self.num_components):\n",
    "            initial_guess = [self.qs[i], self.ss[i], self.ns[i]]\n",
    "\n",
    "            result = minimize(\n",
    "                lambda params: -np.sum(distr_weights[:self.ns[i], i] @ np.log(self.pdf(np.arange(1, self.ns[i]+1).T, params)+ 1)),\n",
    "                initial_guess,\n",
    "                bounds=bounds,\n",
    "                method='Powell',\n",
    "                options={'maxiter': 1000, 'disp': True, 'return_all': False}\n",
    "            )\n",
    "            print(result.x)\n",
    "            self.qs[i], self.ss[i], self.ns[i] = result.x\n",
    "#             print(-np.sum(distr_weights[:, i].reshape(1, self.num_data) * np.log(self.pdf(np.arange(1, self.num_data+1), [self.qs[i], self.ss[i], self.ns[i]])+ 1)) + 1)\n",
    "            self.weights[i] = np.sum(weights[:, i]) / max(self.ns)\n",
    "        # print(sum(self.weights), self.weights)\n",
    "\n",
    "    def iterate(self, max_iter=100, tol=1e-6, verbose=False):\n",
    "        prev_loglikelihood = -np.inf\n",
    "        for i in range(max_iter):\n",
    "            weights = self.Estep()\n",
    "            self.Mstep(weights)\n",
    "            loglikelihood = self.compute_loglikelihood()\n",
    "            if verbose:\n",
    "                print(f'Iteration {i+1}: Log Likelihood = {loglikelihood:.4f}')\n",
    "            # if abs(loglikelihood - prev_loglikelihood) < tol:\n",
    "            #     print(\"Stop\")\n",
    "            #     break\n",
    "            prev_loglikelihood = loglikelihood\n",
    "\n",
    "    def compute_loglikelihood(self):\n",
    "        loglikelihood = 0 \n",
    "        component_probs = [weight * self.pdf(np.arange(1, len(self.data)+1), [q, s, n]) for weight, n, q, s in zip(self.weights, self.ns, self.qs, self.ss)]\n",
    "        sum_probs = sum(component_probs)\n",
    "        for probs in range(len(sum_probs)):\n",
    "            if  sum_probs[probs] == 0:\n",
    "                sum_probs[probs] = 1\n",
    "        loglikelihood += np.sum(np.log(sum_probs))\n",
    "        return loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Альтернативное разделение данных по клаасам литературы\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import chisquare\n",
    "np.random.seed(49)\n",
    "\n",
    "incorr_data = [\"cr09\", \"cj21\", \"cc14\"]\n",
    "\n",
    "results = pd.DataFrame(columns=['Text category', \"chi2\", 'p-value'])\n",
    "for i, cats in enumerate(all_words):\n",
    "    np.random.seed(47) #43, 45, 48\n",
    "    data_cat = np.array(all_words[cats])\n",
    "    data_count = Counter(data_cat)\n",
    "    sorted_data_cat = dict(sorted(data_count.items(), key=lambda item: item[1]))\n",
    "    data_list = np.array(sorted(data_count.values(), reverse=True))\n",
    "    print(cats, data_list)\n",
    "    em_model = ZipfMandelbrotMixtureEM(data_list, num_components=2) #ss = [5.96850158, 4.45832753], qs = [1.8343479, 7.79691], ns = [64295, 49360]\n",
    "    em_model.iterate(max_iter=2, verbose=True)\n",
    "#     lr_model = LinearRegression()\n",
    "#     lr_model.fit(np.array(data_list).reshape(len(data_list), 1), data_list)\n",
    "#     l_result = lr_model.predict(np.array(data_list).reshape(len(data_list), 1))\n",
    "    result = em_model.mix_pdf()\n",
    "    print(\"sum_result: \", sum(result))\n",
    "    result = np.round(result/sum(result), 10)\n",
    "    print(result.shape, data_list.shape)\n",
    "#     print(sum(np.round(data_list, sum(np.round(result/sum(result), 10)), np.round(data_list/sum(data_list), 8)[0], np.round(result, 10)[0])\n",
    "#     chi1 = chi(data_list, result*sum(data_list))\n",
    "    chi2, p = chisquare(result*sum(data_list), data_list)\n",
    "    print(\"What \", chi2, p)\n",
    "    new_row = pd.DataFrame({'Text category': [cats], \"chi2\": [chi2], 'p-value': [p]})\n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "    plt.figure(i)\n",
    "    sns.ecdfplot(data_list[:500])\n",
    "    sns.ecdfplot((np.array(result[:500])*sum(data_list)).astype(int))\n",
    "    plt.title(\"Эмпирическая плотность распределения\")\n",
    "    plt.ylabel(\"Значение эмпирической плотности распределения\")\n",
    "    plt.legend([\"Истинная ЭПР\", \"Рассчитанная ЭПР\"])\n",
    "    plt.show()\n",
    "    plt.figure(i)\n",
    "    plt.bar(range(1, len(data_list[:250])+1), data_list[:250]/sum(data_list))\n",
    "#     for i in range(em_model.num_components):\n",
    "#         z_component = em_model.pdf(np.arange(1, len(data_list[:250])+1), [em_model.qs[i], em_model.ss[i], em_model.ns[0]])\n",
    "#         plt.plot(range(1, len(data_list[:250])+1), z_component, label=f\"Zipf-Mandelbrot {i} component\")\n",
    "    plt.plot(range(len(data_list[:250])), result[:250], label=\"Zipf-Mandelbrot mixture\")\n",
    "#     plt.plot(range(1, len(data_list[:250])+1), l_result[:250]/sum(data_list), label=\"Linear Regression\")\n",
    "    plt.xlabel(\"Ранги слов\")\n",
    "    plt.ylabel(\"Плотность вероятности\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea10c14f-6234-4cdb-85d7-8cd9c0344661",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=['p-value', \"chi2\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0597eeb9-6650-4695-9608-b9fa82b8a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results[\"p-value\"] > 0.05].count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
